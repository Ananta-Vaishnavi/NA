{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e7b69b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-27T18:07:51.515466Z",
     "iopub.status.busy": "2025-01-27T18:07:51.514952Z",
     "iopub.status.idle": "2025-01-27T18:12:18.402470Z",
     "shell.execute_reply": "2025-01-27T18:12:18.401289Z"
    },
    "papermill": {
     "duration": 266.915825,
     "end_time": "2025-01-27T18:12:18.427408",
     "exception": false,
     "start_time": "2025-01-27T18:07:51.511583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output directory at: /kaggle/working/smaller_dataset\n",
      "Scanning /kaggle/input/combined-cropped-fer-dataset/train for class directories...\n",
      "Found classes in train: ['surprise', 'fear', 'angry', 'neutral', 'sad', 'happy']\n",
      "Scanning /kaggle/input/combined-cropped-fer-dataset/test for class directories...\n",
      "Found classes in test: ['surprise', 'fear', 'angry', 'neutral', 'sad', 'happy']\n",
      "Processing each class...\n",
      "Processing class: surprise\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/train/surprise\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/test/surprise\n",
      "Total files found for class surprise: 7590\n",
      "Selected 6991 files for class surprise\n",
      "Created directory for class surprise: /kaggle/working/smaller_dataset/surprise\n",
      "Class surprise: 100/6991 files done\n",
      "Class surprise: 200/6991 files done\n",
      "Class surprise: 300/6991 files done\n",
      "Class surprise: 400/6991 files done\n",
      "Class surprise: 500/6991 files done\n",
      "Class surprise: 600/6991 files done\n",
      "Class surprise: 700/6991 files done\n",
      "Class surprise: 800/6991 files done\n",
      "Class surprise: 900/6991 files done\n",
      "Class surprise: 1000/6991 files done\n",
      "Class surprise: 1100/6991 files done\n",
      "Class surprise: 1200/6991 files done\n",
      "Class surprise: 1300/6991 files done\n",
      "Class surprise: 1400/6991 files done\n",
      "Class surprise: 1500/6991 files done\n",
      "Class surprise: 1600/6991 files done\n",
      "Class surprise: 1700/6991 files done\n",
      "Class surprise: 1800/6991 files done\n",
      "Class surprise: 1900/6991 files done\n",
      "Class surprise: 2000/6991 files done\n",
      "Class surprise: 2100/6991 files done\n",
      "Class surprise: 2200/6991 files done\n",
      "Class surprise: 2300/6991 files done\n",
      "Class surprise: 2400/6991 files done\n",
      "Class surprise: 2500/6991 files done\n",
      "Class surprise: 2600/6991 files done\n",
      "Class surprise: 2700/6991 files done\n",
      "Class surprise: 2800/6991 files done\n",
      "Class surprise: 2900/6991 files done\n",
      "Class surprise: 3000/6991 files done\n",
      "Class surprise: 3100/6991 files done\n",
      "Class surprise: 3200/6991 files done\n",
      "Class surprise: 3300/6991 files done\n",
      "Class surprise: 3400/6991 files done\n",
      "Class surprise: 3500/6991 files done\n",
      "Class surprise: 3600/6991 files done\n",
      "Class surprise: 3700/6991 files done\n",
      "Class surprise: 3800/6991 files done\n",
      "Class surprise: 3900/6991 files done\n",
      "Class surprise: 4000/6991 files done\n",
      "Class surprise: 4100/6991 files done\n",
      "Class surprise: 4200/6991 files done\n",
      "Class surprise: 4300/6991 files done\n",
      "Class surprise: 4400/6991 files done\n",
      "Class surprise: 4500/6991 files done\n",
      "Class surprise: 4600/6991 files done\n",
      "Class surprise: 4700/6991 files done\n",
      "Class surprise: 4800/6991 files done\n",
      "Class surprise: 4900/6991 files done\n",
      "Class surprise: 5000/6991 files done\n",
      "Class surprise: 5100/6991 files done\n",
      "Class surprise: 5200/6991 files done\n",
      "Class surprise: 5300/6991 files done\n",
      "Class surprise: 5400/6991 files done\n",
      "Class surprise: 5500/6991 files done\n",
      "Class surprise: 5600/6991 files done\n",
      "Class surprise: 5700/6991 files done\n",
      "Class surprise: 5800/6991 files done\n",
      "Class surprise: 5900/6991 files done\n",
      "Class surprise: 6000/6991 files done\n",
      "Class surprise: 6100/6991 files done\n",
      "Class surprise: 6200/6991 files done\n",
      "Class surprise: 6300/6991 files done\n",
      "Class surprise: 6400/6991 files done\n",
      "Class surprise: 6500/6991 files done\n",
      "Class surprise: 6600/6991 files done\n",
      "Class surprise: 6700/6991 files done\n",
      "Class surprise: 6800/6991 files done\n",
      "Class surprise: 6900/6991 files done\n",
      "Class surprise: 6991/6991 files done\n",
      "Finished processing class: surprise\n",
      "Processing class: fear\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/train/fear\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/test/fear\n",
      "Total files found for class fear: 7113\n",
      "Selected 6991 files for class fear\n",
      "Created directory for class fear: /kaggle/working/smaller_dataset/fear\n",
      "Class fear: 100/6991 files done\n",
      "Class fear: 200/6991 files done\n",
      "Class fear: 300/6991 files done\n",
      "Class fear: 400/6991 files done\n",
      "Class fear: 500/6991 files done\n",
      "Class fear: 600/6991 files done\n",
      "Class fear: 700/6991 files done\n",
      "Class fear: 800/6991 files done\n",
      "Class fear: 900/6991 files done\n",
      "Class fear: 1000/6991 files done\n",
      "Class fear: 1100/6991 files done\n",
      "Class fear: 1200/6991 files done\n",
      "Class fear: 1300/6991 files done\n",
      "Class fear: 1400/6991 files done\n",
      "Class fear: 1500/6991 files done\n",
      "Class fear: 1600/6991 files done\n",
      "Class fear: 1700/6991 files done\n",
      "Class fear: 1800/6991 files done\n",
      "Class fear: 1900/6991 files done\n",
      "Class fear: 2000/6991 files done\n",
      "Class fear: 2100/6991 files done\n",
      "Class fear: 2200/6991 files done\n",
      "Class fear: 2300/6991 files done\n",
      "Class fear: 2400/6991 files done\n",
      "Class fear: 2500/6991 files done\n",
      "Class fear: 2600/6991 files done\n",
      "Class fear: 2700/6991 files done\n",
      "Class fear: 2800/6991 files done\n",
      "Class fear: 2900/6991 files done\n",
      "Class fear: 3000/6991 files done\n",
      "Class fear: 3100/6991 files done\n",
      "Class fear: 3200/6991 files done\n",
      "Class fear: 3300/6991 files done\n",
      "Class fear: 3400/6991 files done\n",
      "Class fear: 3500/6991 files done\n",
      "Class fear: 3600/6991 files done\n",
      "Class fear: 3700/6991 files done\n",
      "Class fear: 3800/6991 files done\n",
      "Class fear: 3900/6991 files done\n",
      "Class fear: 4000/6991 files done\n",
      "Class fear: 4100/6991 files done\n",
      "Class fear: 4200/6991 files done\n",
      "Class fear: 4300/6991 files done\n",
      "Class fear: 4400/6991 files done\n",
      "Class fear: 4500/6991 files done\n",
      "Class fear: 4600/6991 files done\n",
      "Class fear: 4700/6991 files done\n",
      "Class fear: 4800/6991 files done\n",
      "Class fear: 4900/6991 files done\n",
      "Class fear: 5000/6991 files done\n",
      "Class fear: 5100/6991 files done\n",
      "Class fear: 5200/6991 files done\n",
      "Class fear: 5300/6991 files done\n",
      "Class fear: 5400/6991 files done\n",
      "Class fear: 5500/6991 files done\n",
      "Class fear: 5600/6991 files done\n",
      "Class fear: 5700/6991 files done\n",
      "Class fear: 5800/6991 files done\n",
      "Class fear: 5900/6991 files done\n",
      "Class fear: 6000/6991 files done\n",
      "Class fear: 6100/6991 files done\n",
      "Class fear: 6200/6991 files done\n",
      "Class fear: 6300/6991 files done\n",
      "Class fear: 6400/6991 files done\n",
      "Class fear: 6500/6991 files done\n",
      "Class fear: 6600/6991 files done\n",
      "Class fear: 6700/6991 files done\n",
      "Class fear: 6800/6991 files done\n",
      "Class fear: 6900/6991 files done\n",
      "Class fear: 6991/6991 files done\n",
      "Finished processing class: fear\n",
      "Processing class: angry\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/train/angry\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/test/angry\n",
      "Total files found for class angry: 7304\n",
      "Selected 6991 files for class angry\n",
      "Created directory for class angry: /kaggle/working/smaller_dataset/angry\n",
      "Class angry: 100/6991 files done\n",
      "Class angry: 200/6991 files done\n",
      "Class angry: 300/6991 files done\n",
      "Class angry: 400/6991 files done\n",
      "Class angry: 500/6991 files done\n",
      "Class angry: 600/6991 files done\n",
      "Class angry: 700/6991 files done\n",
      "Class angry: 800/6991 files done\n",
      "Class angry: 900/6991 files done\n",
      "Class angry: 1000/6991 files done\n",
      "Class angry: 1100/6991 files done\n",
      "Class angry: 1200/6991 files done\n",
      "Class angry: 1300/6991 files done\n",
      "Class angry: 1400/6991 files done\n",
      "Class angry: 1500/6991 files done\n",
      "Class angry: 1600/6991 files done\n",
      "Class angry: 1700/6991 files done\n",
      "Class angry: 1800/6991 files done\n",
      "Class angry: 1900/6991 files done\n",
      "Class angry: 2000/6991 files done\n",
      "Class angry: 2100/6991 files done\n",
      "Class angry: 2200/6991 files done\n",
      "Class angry: 2300/6991 files done\n",
      "Class angry: 2400/6991 files done\n",
      "Class angry: 2500/6991 files done\n",
      "Class angry: 2600/6991 files done\n",
      "Class angry: 2700/6991 files done\n",
      "Class angry: 2800/6991 files done\n",
      "Class angry: 2900/6991 files done\n",
      "Class angry: 3000/6991 files done\n",
      "Class angry: 3100/6991 files done\n",
      "Class angry: 3200/6991 files done\n",
      "Class angry: 3300/6991 files done\n",
      "Class angry: 3400/6991 files done\n",
      "Class angry: 3500/6991 files done\n",
      "Class angry: 3600/6991 files done\n",
      "Class angry: 3700/6991 files done\n",
      "Class angry: 3800/6991 files done\n",
      "Class angry: 3900/6991 files done\n",
      "Class angry: 4000/6991 files done\n",
      "Class angry: 4100/6991 files done\n",
      "Class angry: 4200/6991 files done\n",
      "Class angry: 4300/6991 files done\n",
      "Class angry: 4400/6991 files done\n",
      "Class angry: 4500/6991 files done\n",
      "Class angry: 4600/6991 files done\n",
      "Class angry: 4700/6991 files done\n",
      "Class angry: 4800/6991 files done\n",
      "Class angry: 4900/6991 files done\n",
      "Class angry: 5000/6991 files done\n",
      "Class angry: 5100/6991 files done\n",
      "Class angry: 5200/6991 files done\n",
      "Class angry: 5300/6991 files done\n",
      "Class angry: 5400/6991 files done\n",
      "Class angry: 5500/6991 files done\n",
      "Class angry: 5600/6991 files done\n",
      "Class angry: 5700/6991 files done\n",
      "Class angry: 5800/6991 files done\n",
      "Class angry: 5900/6991 files done\n",
      "Class angry: 6000/6991 files done\n",
      "Class angry: 6100/6991 files done\n",
      "Class angry: 6200/6991 files done\n",
      "Class angry: 6300/6991 files done\n",
      "Class angry: 6400/6991 files done\n",
      "Class angry: 6500/6991 files done\n",
      "Class angry: 6600/6991 files done\n",
      "Class angry: 6700/6991 files done\n",
      "Class angry: 6800/6991 files done\n",
      "Class angry: 6900/6991 files done\n",
      "Class angry: 6991/6991 files done\n",
      "Finished processing class: angry\n",
      "Processing class: neutral\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/train/neutral\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/test/neutral\n",
      "Total files found for class neutral: 7845\n",
      "Selected 6991 files for class neutral\n",
      "Created directory for class neutral: /kaggle/working/smaller_dataset/neutral\n",
      "Class neutral: 100/6991 files done\n",
      "Class neutral: 200/6991 files done\n",
      "Class neutral: 300/6991 files done\n",
      "Class neutral: 400/6991 files done\n",
      "Class neutral: 500/6991 files done\n",
      "Class neutral: 600/6991 files done\n",
      "Class neutral: 700/6991 files done\n",
      "Class neutral: 800/6991 files done\n",
      "Class neutral: 900/6991 files done\n",
      "Class neutral: 1000/6991 files done\n",
      "Class neutral: 1100/6991 files done\n",
      "Class neutral: 1200/6991 files done\n",
      "Class neutral: 1300/6991 files done\n",
      "Class neutral: 1400/6991 files done\n",
      "Class neutral: 1500/6991 files done\n",
      "Class neutral: 1600/6991 files done\n",
      "Class neutral: 1700/6991 files done\n",
      "Class neutral: 1800/6991 files done\n",
      "Class neutral: 1900/6991 files done\n",
      "Class neutral: 2000/6991 files done\n",
      "Class neutral: 2100/6991 files done\n",
      "Class neutral: 2200/6991 files done\n",
      "Class neutral: 2300/6991 files done\n",
      "Class neutral: 2400/6991 files done\n",
      "Class neutral: 2500/6991 files done\n",
      "Class neutral: 2600/6991 files done\n",
      "Class neutral: 2700/6991 files done\n",
      "Class neutral: 2800/6991 files done\n",
      "Class neutral: 2900/6991 files done\n",
      "Class neutral: 3000/6991 files done\n",
      "Class neutral: 3100/6991 files done\n",
      "Class neutral: 3200/6991 files done\n",
      "Class neutral: 3300/6991 files done\n",
      "Class neutral: 3400/6991 files done\n",
      "Class neutral: 3500/6991 files done\n",
      "Class neutral: 3600/6991 files done\n",
      "Class neutral: 3700/6991 files done\n",
      "Class neutral: 3800/6991 files done\n",
      "Class neutral: 3900/6991 files done\n",
      "Class neutral: 4000/6991 files done\n",
      "Class neutral: 4100/6991 files done\n",
      "Class neutral: 4200/6991 files done\n",
      "Class neutral: 4300/6991 files done\n",
      "Class neutral: 4400/6991 files done\n",
      "Class neutral: 4500/6991 files done\n",
      "Class neutral: 4600/6991 files done\n",
      "Class neutral: 4700/6991 files done\n",
      "Class neutral: 4800/6991 files done\n",
      "Class neutral: 4900/6991 files done\n",
      "Class neutral: 5000/6991 files done\n",
      "Class neutral: 5100/6991 files done\n",
      "Class neutral: 5200/6991 files done\n",
      "Class neutral: 5300/6991 files done\n",
      "Class neutral: 5400/6991 files done\n",
      "Class neutral: 5500/6991 files done\n",
      "Class neutral: 5600/6991 files done\n",
      "Class neutral: 5700/6991 files done\n",
      "Class neutral: 5800/6991 files done\n",
      "Class neutral: 5900/6991 files done\n",
      "Class neutral: 6000/6991 files done\n",
      "Class neutral: 6100/6991 files done\n",
      "Class neutral: 6200/6991 files done\n",
      "Class neutral: 6300/6991 files done\n",
      "Class neutral: 6400/6991 files done\n",
      "Class neutral: 6500/6991 files done\n",
      "Class neutral: 6600/6991 files done\n",
      "Class neutral: 6700/6991 files done\n",
      "Class neutral: 6800/6991 files done\n",
      "Class neutral: 6900/6991 files done\n",
      "Class neutral: 6991/6991 files done\n",
      "Finished processing class: neutral\n",
      "Processing class: sad\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/train/sad\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/test/sad\n",
      "Total files found for class sad: 6991\n",
      "Selected 6991 files for class sad\n",
      "Created directory for class sad: /kaggle/working/smaller_dataset/sad\n",
      "Class sad: 100/6991 files done\n",
      "Class sad: 200/6991 files done\n",
      "Class sad: 300/6991 files done\n",
      "Class sad: 400/6991 files done\n",
      "Class sad: 500/6991 files done\n",
      "Class sad: 600/6991 files done\n",
      "Class sad: 700/6991 files done\n",
      "Class sad: 800/6991 files done\n",
      "Class sad: 900/6991 files done\n",
      "Class sad: 1000/6991 files done\n",
      "Class sad: 1100/6991 files done\n",
      "Class sad: 1200/6991 files done\n",
      "Class sad: 1300/6991 files done\n",
      "Class sad: 1400/6991 files done\n",
      "Class sad: 1500/6991 files done\n",
      "Class sad: 1600/6991 files done\n",
      "Class sad: 1700/6991 files done\n",
      "Class sad: 1800/6991 files done\n",
      "Class sad: 1900/6991 files done\n",
      "Class sad: 2000/6991 files done\n",
      "Class sad: 2100/6991 files done\n",
      "Class sad: 2200/6991 files done\n",
      "Class sad: 2300/6991 files done\n",
      "Class sad: 2400/6991 files done\n",
      "Class sad: 2500/6991 files done\n",
      "Class sad: 2600/6991 files done\n",
      "Class sad: 2700/6991 files done\n",
      "Class sad: 2800/6991 files done\n",
      "Class sad: 2900/6991 files done\n",
      "Class sad: 3000/6991 files done\n",
      "Class sad: 3100/6991 files done\n",
      "Class sad: 3200/6991 files done\n",
      "Class sad: 3300/6991 files done\n",
      "Class sad: 3400/6991 files done\n",
      "Class sad: 3500/6991 files done\n",
      "Class sad: 3600/6991 files done\n",
      "Class sad: 3700/6991 files done\n",
      "Class sad: 3800/6991 files done\n",
      "Class sad: 3900/6991 files done\n",
      "Class sad: 4000/6991 files done\n",
      "Class sad: 4100/6991 files done\n",
      "Class sad: 4200/6991 files done\n",
      "Class sad: 4300/6991 files done\n",
      "Class sad: 4400/6991 files done\n",
      "Class sad: 4500/6991 files done\n",
      "Class sad: 4600/6991 files done\n",
      "Class sad: 4700/6991 files done\n",
      "Class sad: 4800/6991 files done\n",
      "Class sad: 4900/6991 files done\n",
      "Class sad: 5000/6991 files done\n",
      "Class sad: 5100/6991 files done\n",
      "Class sad: 5200/6991 files done\n",
      "Class sad: 5300/6991 files done\n",
      "Class sad: 5400/6991 files done\n",
      "Class sad: 5500/6991 files done\n",
      "Class sad: 5600/6991 files done\n",
      "Class sad: 5700/6991 files done\n",
      "Class sad: 5800/6991 files done\n",
      "Class sad: 5900/6991 files done\n",
      "Class sad: 6000/6991 files done\n",
      "Class sad: 6100/6991 files done\n",
      "Class sad: 6200/6991 files done\n",
      "Class sad: 6300/6991 files done\n",
      "Class sad: 6400/6991 files done\n",
      "Class sad: 6500/6991 files done\n",
      "Class sad: 6600/6991 files done\n",
      "Class sad: 6700/6991 files done\n",
      "Class sad: 6800/6991 files done\n",
      "Class sad: 6900/6991 files done\n",
      "Class sad: 6991/6991 files done\n",
      "Finished processing class: sad\n",
      "Processing class: happy\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/train/happy\n",
      "Collecting files from: /kaggle/input/combined-cropped-fer-dataset/test/happy\n",
      "Total files found for class happy: 7554\n",
      "Selected 6991 files for class happy\n",
      "Created directory for class happy: /kaggle/working/smaller_dataset/happy\n",
      "Class happy: 100/6991 files done\n",
      "Class happy: 200/6991 files done\n",
      "Class happy: 300/6991 files done\n",
      "Class happy: 400/6991 files done\n",
      "Class happy: 500/6991 files done\n",
      "Class happy: 600/6991 files done\n",
      "Class happy: 700/6991 files done\n",
      "Class happy: 800/6991 files done\n",
      "Class happy: 900/6991 files done\n",
      "Class happy: 1000/6991 files done\n",
      "Class happy: 1100/6991 files done\n",
      "Class happy: 1200/6991 files done\n",
      "Class happy: 1300/6991 files done\n",
      "Class happy: 1400/6991 files done\n",
      "Class happy: 1500/6991 files done\n",
      "Class happy: 1600/6991 files done\n",
      "Class happy: 1700/6991 files done\n",
      "Class happy: 1800/6991 files done\n",
      "Class happy: 1900/6991 files done\n",
      "Class happy: 2000/6991 files done\n",
      "Class happy: 2100/6991 files done\n",
      "Class happy: 2200/6991 files done\n",
      "Class happy: 2300/6991 files done\n",
      "Class happy: 2400/6991 files done\n",
      "Class happy: 2500/6991 files done\n",
      "Class happy: 2600/6991 files done\n",
      "Class happy: 2700/6991 files done\n",
      "Class happy: 2800/6991 files done\n",
      "Class happy: 2900/6991 files done\n",
      "Class happy: 3000/6991 files done\n",
      "Class happy: 3100/6991 files done\n",
      "Class happy: 3200/6991 files done\n",
      "Class happy: 3300/6991 files done\n",
      "Class happy: 3400/6991 files done\n",
      "Class happy: 3500/6991 files done\n",
      "Class happy: 3600/6991 files done\n",
      "Class happy: 3700/6991 files done\n",
      "Class happy: 3800/6991 files done\n",
      "Class happy: 3900/6991 files done\n",
      "Class happy: 4000/6991 files done\n",
      "Class happy: 4100/6991 files done\n",
      "Class happy: 4200/6991 files done\n",
      "Class happy: 4300/6991 files done\n",
      "Class happy: 4400/6991 files done\n",
      "Class happy: 4500/6991 files done\n",
      "Class happy: 4600/6991 files done\n",
      "Class happy: 4700/6991 files done\n",
      "Class happy: 4800/6991 files done\n",
      "Class happy: 4900/6991 files done\n",
      "Class happy: 5000/6991 files done\n",
      "Class happy: 5100/6991 files done\n",
      "Class happy: 5200/6991 files done\n",
      "Class happy: 5300/6991 files done\n",
      "Class happy: 5400/6991 files done\n",
      "Class happy: 5500/6991 files done\n",
      "Class happy: 5600/6991 files done\n",
      "Class happy: 5700/6991 files done\n",
      "Class happy: 5800/6991 files done\n",
      "Class happy: 5900/6991 files done\n",
      "Class happy: 6000/6991 files done\n",
      "Class happy: 6100/6991 files done\n",
      "Class happy: 6200/6991 files done\n",
      "Class happy: 6300/6991 files done\n",
      "Class happy: 6400/6991 files done\n",
      "Class happy: 6500/6991 files done\n",
      "Class happy: 6600/6991 files done\n",
      "Class happy: 6700/6991 files done\n",
      "Class happy: 6800/6991 files done\n",
      "Class happy: 6900/6991 files done\n",
      "Class happy: 6991/6991 files done\n",
      "Finished processing class: happy\n",
      "Creating zip file: /kaggle/working/smaller_dataset.zip\n",
      "Dataset successfully zipped at: /kaggle/working/smaller_dataset.zip\n",
      "Completed dataset creation. Consolidated dataset is available at: /kaggle/working/smaller_dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil  # For copying files\n",
    "\n",
    "\n",
    "def create_small_dataset(original_dataset_path, output_path, size_per_class=4740):\n",
    "    # Path for the consolidated dataset\n",
    "    dataset_output_path = os.path.join(output_path, 'smaller_dataset')\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(dataset_output_path, exist_ok=True)\n",
    "    print(f\"Created output directory at: {dataset_output_path}\")\n",
    "\n",
    "    # List all class directories in both Train and Test\n",
    "    class_directories = {}\n",
    "    for subfolder in ['train', 'test']:\n",
    "        subfolder_path = os.path.join(original_dataset_path, subfolder)\n",
    "        if os.path.exists(subfolder_path):\n",
    "            print(f\"Scanning {subfolder_path} for class directories...\")\n",
    "            for class_name in os.listdir(subfolder_path):\n",
    "                class_path = os.path.join(subfolder_path, class_name)\n",
    "                if os.path.isdir(class_path):\n",
    "                    if class_name not in class_directories:\n",
    "                        class_directories[class_name] = []\n",
    "                    class_directories[class_name].append(class_path)\n",
    "            print(f\"Found classes in {subfolder}: {list(class_directories.keys())}\")\n",
    "\n",
    "    # Process all classes\n",
    "    print(\"Processing each class...\")\n",
    "    for class_name, paths in class_directories.items():\n",
    "        print(f\"Processing class: {class_name}\")\n",
    "        all_files = []\n",
    "        for path in paths:\n",
    "            print(f\"Collecting files from: {path}\")\n",
    "            files = [os.path.join(path, file) for file in os.listdir(path) if os.path.isfile(os.path.join(path, file))]\n",
    "            all_files.extend(files)\n",
    "        print(f\"Total files found for class {class_name}: {len(all_files)}\")\n",
    "\n",
    "        # Shuffle and select up to size_per_class files\n",
    "        selected_files = all_files[:min(len(all_files), size_per_class)]\n",
    "        print(f\"Selected {len(selected_files)} files for class {class_name}\")\n",
    "\n",
    "        # Create class directory in the consolidated folder\n",
    "        class_output_path = os.path.join(dataset_output_path, class_name)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "        print(f\"Created directory for class {class_name}: {class_output_path}\")\n",
    "\n",
    "        # Copy selected files, with progress logging\n",
    "        for idx, file in enumerate(selected_files, 1):  # Add 1 to make it 1-indexed\n",
    "            output_file_path = os.path.join(class_output_path, os.path.basename(file))\n",
    "            shutil.copy(file, output_file_path)\n",
    "            if idx % 100 == 0 or idx == len(selected_files):  # Log every 100 files or at the end\n",
    "                print(f\"Class {class_name}: {idx}/{len(selected_files)} files done\")\n",
    "\n",
    "        print(f\"Finished processing class: {class_name}\")\n",
    "\n",
    "    # Create a zip file of the smaller dataset\n",
    "    zip_file_path = os.path.join(output_path, 'smaller_dataset.zip')\n",
    "    print(f\"Creating zip file: {zip_file_path}\")\n",
    "    with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(dataset_output_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, dataset_output_path)\n",
    "                zipf.write(file_path, arcname)\n",
    "    print(f\"Dataset successfully zipped at: {zip_file_path}\")\n",
    "\n",
    "    print(f\"Completed dataset creation. Consolidated dataset is available at: {dataset_output_path}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "original_dataset_path = \"/kaggle/input/combined-cropped-fer-dataset\"  # Adjust this path\n",
    "output_path = \"/kaggle/working/\"  # Adjust this path\n",
    "\n",
    "create_small_dataset(original_dataset_path, output_path, size_per_class=6991)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6409409,
     "sourceId": 10350433,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6557679,
     "sourceId": 10594961,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 270.419522,
   "end_time": "2025-01-27T18:12:18.971813",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-27T18:07:48.552291",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
