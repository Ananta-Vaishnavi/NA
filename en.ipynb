{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10585265,"sourceType":"datasetVersion","datasetId":6550772},{"sourceId":10594961,"sourceType":"datasetVersion","datasetId":6557679}],"dockerImageVersionId":30461,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as npy # linear algebra\nimport pandas as pds # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as ImgDataGen\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-01-27T16:47:29.614964Z","iopub.execute_input":"2025-01-27T16:47:29.615481Z","iopub.status.idle":"2025-01-27T16:47:29.621700Z","shell.execute_reply.started":"2025-01-27T16:47:29.615445Z","shell.execute_reply":"2025-01-27T16:47:29.620636Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Specify important directories\nimport os, sys, time, warnings, sklearn\nROOT='/kaggle/input'\n# ROOT='data'\nTRAIN_PATH=ROOT+'/kaggle/input/combined-cropped-fer-dataset/train'\nTEST_PATH=ROOT+'/kaggle/input/combined-cropped-fer-dataset/test'\n# TRAIN_PATH=ROOT+'/fer-2013-images/train'\n# TEST_PATH=ROOT+'/fer-2013-images/test'\ntrain_angry_img_path=TRAIN_PATH +'/angry'\n\nOVERSAMPLED_TRAIN_PATH='fed_oversampled_train'\nMODEL_PATH='models'\nIMAGE_PATH='images'\n\n#  TensorFlow Checkpoint save_weight uses .ckpt extension format\ndef checkpoint_path(model_name):\n    # !mkdir models\n    checkpoint_path = MODEL_PATH+\"/fedav_best_model-\"+model_name+\".ckpt\"\n    return checkpoint_path\n    \n","metadata":{"execution":{"iopub.status.busy":"2025-01-27T16:47:29.623553Z","iopub.execute_input":"2025-01-27T16:47:29.623858Z","iopub.status.idle":"2025-01-27T16:47:29.639271Z","shell.execute_reply.started":"2025-01-27T16:47:29.623829Z","shell.execute_reply":"2025-01-27T16:47:29.638461Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load a sample image \n# using open() to open images\nimage_data = Image.open(\"/kaggle/input/combined-cropped-fer-dataset/train/angry/PrivateTest_12008383.jpg\")\nimage_data","metadata":{"execution":{"iopub.status.busy":"2025-01-27T16:47:29.640861Z","iopub.execute_input":"2025-01-27T16:47:29.641132Z","iopub.status.idle":"2025-01-27T16:47:29.716462Z","shell.execute_reply.started":"2025-01-27T16:47:29.641094Z","shell.execute_reply":"2025-01-27T16:47:29.715517Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the shape of the image\nimage=plt.imread(\"/kaggle/input/combined-cropped-fer-dataset/train/angry/PrivateTest_12008383.jpg\")\nprint(f'Image shape: {image.shape}')\n\n# Convert image data (like jpeg) to numpy using asarray()\nimage_array = npy.asarray(image_data)\nprint(f'Image data array: {image_array}')\n\n# Get the shape of the image array\nprint(f'Image array shape: {image_array.shape}')\n\n# Printing the image \nplt.imshow(image_array)\nplt.xlabel('Width')\nplt.ylabel('Height')\nplt.title('An Angry Face')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-01-27T16:47:29.717763Z","iopub.execute_input":"2025-01-27T16:47:29.718059Z","iopub.status.idle":"2025-01-27T16:47:30.017576Z","shell.execute_reply.started":"2025-01-27T16:47:29.718032Z","shell.execute_reply":"2025-01-27T16:47:30.016403Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the list of folders in the directory as classes\nclasses=os.listdir(TRAIN_PATH+'/')\nclasses","metadata":{"execution":{"iopub.status.busy":"2025-01-27T16:47:30.019874Z","iopub.execute_input":"2025-01-27T16:47:30.020194Z","iopub.status.idle":"2025-01-27T16:47:30.028616Z","shell.execute_reply.started":"2025-01-27T16:47:30.020163Z","shell.execute_reply":"2025-01-27T16:47:30.027535Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get dictionary list of image count per class\ndef class_sample(type):\n    if type.lower() == 'test' or type.lower() == 'train':\n        path=''\n        if type.lower() == 'train':    \n            path= TRAIN_PATH\n        else:\n            path= TEST_PATH\n        \n        filepath=path+'/'\n        class_count = []\n        class_dict ={}\n        for folder in os.listdir(filepath) :\n              class_count.append(len(os.listdir(filepath+folder)))\n              class_dict[folder]=len(os.listdir(filepath+folder))\n        class_total = sum(class_count)\n        return class_total, class_count, class_dict\n    else:\n        raise ValueError('Invalid type. Must be \"test\" or \"train\".')\n\n\ndef test_train_distribution():\n      print(\"---- Train Set ----\")\n      avg_train=class_sample('train')[0]/len(class_sample('train')[1])\n      print(f'Train class distribution:\\n{class_sample(\"train\")[2]}')\n      print(\"Average train class: \",round(avg_train))    \n      print('Total train: ', class_sample('train')[0])\n\n      print(\"\\n---- Test Set ----\")\n      avg_test=class_sample('test')[0]/len(class_sample('test')[1])\n      print(f'Test class distribution:\\n{class_sample(\"test\")[2]}')\n      print(\"Average test class: \",round(avg_test)) \n      print('Total test: ', class_sample('test')[0])\n\n\ntest_train_distribution()\n\n# test_samples=class_sample('test')[0]\n# test_batch_size=sorted([int(test_samples/n) for n in range(1,test_samples+1) if test_samples % n ==0 and test_samples/n<=80],reverse=True)[0]  \n","metadata":{"execution":{"iopub.status.busy":"2025-01-27T16:47:30.029894Z","iopub.execute_input":"2025-01-27T16:47:30.030158Z","iopub.status.idle":"2025-01-27T16:47:30.401171Z","shell.execute_reply.started":"2025-01-27T16:47:30.030132Z","shell.execute_reply":"2025-01-27T16:47:30.400016Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pds.DataFrame(list(class_sample(\"train\")[2].items()), columns=['Emotion', 'Count'])\ndf_train.index.name = 'Emotion'\ndf_test = pds.DataFrame(list(class_sample(\"test\")[2].items()), columns=['Emotion', 'Count'])\ndf_test.index.name = 'Emotion'\n\n\n# plot a barplot with vertical orientation\nsns.set()\nplt.figure(figsize=(20, 8))\nplt.subplot(1, 2, 1)\naxis = sns.barplot(x='Emotion', y='Count', data=df_train, orient='v')\n# set labels and title\nplt.xlabel(\"Facial Expression\", fontsize=15)\nplt.ylabel(\"Count\", fontsize=15)\nplt.title(\"(a). Distribution of The Train Images\", fontsize=20)\n# plt.legend( df_train.Emotion, loc='upper left')\n# set x-axis tick labels\n# axis.set_xticks(range(len(df_train.Emotion)), df_train.Emotion)\n# axis.yaxis.set_major_locator(ticker.MultipleLocator(2.5))\n\nplt.subplot(1, 2, 2)\nsns.barplot(x='Emotion', y='Count', data=df_test, orient='v')\nplt.xlabel(\"Facial Expression\", fontsize=15)\nplt.ylabel(\"Count\", fontsize=15)\nplt.title(\"(b). Distribution of The Test Images\", fontsize=20)\nplt.show()\n\nprint('\\n\\n')\n\nx_train = npy.array([ len(os.listdir(TRAIN_PATH+'/'+class_name+'/')) for class_name in classes])\nx_test = npy.array([ len(os.listdir(TEST_PATH+'/'+class_name+'/')) for class_name in classes])\nlabel = classes\n  \n# plot a Pie plot with vertical orientation\nplt.figure(figsize=(20, 8))\nax = plt.subplot(1, 2, 1)\nplt.pie(x_train, labels=label, autopct='%1.1f%%', startangle=90)\nax.set_title('(a). Pie Plot of The Train Images', fontsize=20)\n\nay = plt.subplot(1, 2, 2)\nplt.pie(x_test, labels=label, autopct='%1.1f%%', startangle=90)\nay.set_title('(b). Pie Plot of The Test Images', fontsize=20)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2025-01-27T16:47:30.402285Z","iopub.execute_input":"2025-01-27T16:47:30.402551Z","iopub.status.idle":"2025-01-27T16:47:31.060891Z","shell.execute_reply.started":"2025-01-27T16:47:30.402524Z","shell.execute_reply":"2025-01-27T16:47:31.059880Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div>\n    <h2 style = \"padding: 3px; \n                 color: #256d7c;\n                 font-size: 30px;\n                 font-family: Cambria;\n                 font-weight: bold;\">Data Augmentation\n    </h2>\n</div>","metadata":{}},{"cell_type":"code","source":"target_size=(48, 48)\n# target_size=(224, 224)\nbatch_size=32\n\n## Train Image Data Generator instance. \n# We will not apply any transformon specific orientations or features and no initial rescale to the image\n# We'll only split the image data into train and validation set\ntrainValidation_data_generator = ImgDataGen(\n                                            # rescale=1./225,\n                                            rotation_range=10,  # Randomly rotate images by up to 10 degrees\n                                            zoom_range=0.2,  # Randomly zoom images by up to 20%\n                                            width_shift_range=0.1,  # Randomly shift images horizontally by up to 10% of the image width\n                                            height_shift_range=0.1,  # Randomly shift images vertically by up to 10% of the image height\n                                            shear_range=0.2,  # Randomly apply shearing transformations\n                                            horizontal_flip=True,  # Randomly flip images horizontally\n                                            fill_mode='nearest',  # Fill in missing pixels with the nearest value\n                                            validation_split=0.2    # set the validation split                                \n                                            )\n\n\n# Test Image Data Generator instance for Test data\ntest_data_generator = ImgDataGen(\n                                # rescale = 1./255,\n                                )\n\n# Set a random seed to synchronize the shuffle order across different runs of the generator\n# trainValidation_data_generator.set_seed(42)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Successfully mapped the train-images to their classes from the dataframe. Now let's do the same for the test-images. \n# Here, I will only be rescaling. No other transformations are applies, to preserve originality of the images.\n\nclasses = ['angry', 'fearful', 'happy', 'sad', 'surprised']\n\n## Mapping images to their classes.\nprint('Train Set Generated - ',end=' ') \ntrain_generator = trainValidation_data_generator.flow_from_directory(\n                                                            directory=OVERSAMPLED_TRAIN_PATH, \n                                                            # directory=TRAIN_PATH, \n                                                            target_size=target_size,\n                                                            batch_size=batch_size,\n                                                            class_mode='categorical', \n                                                            color_mode='rgb', \n                                                            classes=classes,\n                                                            shuffle=True, \n                                                            subset='training' # set as training data\n                                                        )\n## Mapping images to their classes.\nprint('Validation Set Generated - ',end=' ') \nvalidation_generator = trainValidation_data_generator.flow_from_directory(\n                                                            # directory=TRAIN_PATH, \n                                                            directory=OVERSAMPLED_TRAIN_PATH, \n                                                            target_size=target_size,\n                                                            batch_size=batch_size,\n                                                            class_mode='categorical', \n                                                            color_mode='rgb', \n                                                            classes= classes,\n                                                            shuffle=False, \n                                                            subset='validation' # set as validation data\n                                                        )\ntest_samples=class_sample('test')[0]\ntest_batch_size=batch_size\ntest_steps=int(test_samples/test_batch_size)\n\n## Mapping images to their classes.\nprint('Test Set Generated - ',end=' ') \ntest_generator = test_data_generator.flow_from_directory(\n                                        directory=TEST_PATH, \n                                        target_size=target_size,\n                                        class_mode='categorical', \n                                        color_mode='rgb', \n                                        classes=classes,\n                                        shuffle=False, \n                                        batch_size=test_batch_size\n                                        )\n\n## Mapping shuffled images to their classes.\nprint('Shuffled Test Set Generated - ',end=' ') \ntest_generator_shuffled = test_data_generator.flow_from_directory(\n                                        TEST_PATH, \n                                        target_size=target_size,\n                                        class_mode='categorical', \n                                        color_mode='rgb', \n                                        classes=classes,\n                                        shuffle=True, \n                                        batch_size=test_batch_size\n                                        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# From the generator we can get information we will need later\n# classes=  # os.listdir(TRAIN_PATH+'/')\nclass_dictionary = train_generator.class_indices\nclass_keys = list(train_generator.class_indices.keys())\nclass_values = list(train_generator.class_indices.values())\nclass_count = len(class_keys)\n\nprint ('test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)\n\ntrain_images, train_labels = next(train_generator)\nvalidation_images, validation_labels = next(validation_generator)\ntest_images, test_labels = next(test_generator)\n\nprint(f'\\nThere are 7 classes: {classes}')\nprint(f'The class dictionary are: {class_dictionary}')\nprint('Class count: ', class_count)\n\nprint('\\nX_train shape: ', train_images.shape)\nprint('y_train shape: ', train_labels.shape)\nprint('\\nX_test shape: ', test_images.shape)\nprint('y_test shape: ', test_labels.shape)\n\nprint('\\ntrain_generator sample: ', train_generator.samples)\nprint('validation_generator sample: ', validation_generator.samples)\nprint('test_generator sample: ', test_generator.samples)\n\nprint('\\ntrain_generator sample: ', train_generator.labels)\nprint('validation_generator sample: ', validation_generator.labels)\nprint('test_generator sample: ', test_generator.labels)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_indices = train_generator.class_indices\nclass_counts = {class_name: 0 for class_name in class_indices}\nnum_images = train_generator.samples\n\nbatch_size = train_generator.batch_size\nnum_batches = len(train_generator)\n\nfor i in range(num_batches):\n    batch = next(train_generator)\n    images, labels = batch\n    for j in range(len(labels)):\n        label = npy.argmax(labels[j])  # convert one-hot encoding to integer label\n        class_name = list(class_indices.keys())[list(class_indices.values()).index(label)]\n        class_counts[class_name] += 1\n\nprint(class_counts)\nprint(f\"Total number of images in train generator: {num_images}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train_gen = pds.DataFrame(list(class_counts.items()), columns=['Emotion', 'Count'])\ndf_train_gen.index.name = 'Emotion'\n\n\n# plot a barplot with vertical orientation\nsns.set()\nplt.figure(figsize=(20, 8))\nsns.barplot(x='Emotion', y='Count', data=df_train_gen, orient='v')\nplt.xlabel(\"Facial Expression\", fontsize=15)\nplt.ylabel(\"Count\", fontsize=15)\nplt.title(\"Balanced Distribution of Train Images with Oversampling Techniques\", fontsize=20)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the sample images, labels, and their filenames \n# To get the correct filename, turn off the shuffle\ndef plotImageWithNames(gen):\n    images, labels = next(gen)\n    filenames = gen.filenames\n    classes = list(gen.class_indices.keys())\n    \n    plt.figure(figsize=(20, 30))\n    length=len(labels)\n    if length<32:  \n        r=length\n    else:\n        r=32\n    for i in range(r):        \n        plt.subplot(7, 5, i + 1)\n        image=images[i] /255\n        plt.imshow(image)\n        index=npy.argmax(labels[i])\n        class_name=classes[index]\n        filename=gen.filenames[i]\n        plt.title(\n                    label=f\"{class_name}\", # \\n{filename} \", \n                    color='blue', \n                    fontsize=20\n                    )\n        plt.axis('off')\n    plt.show()\n\nplotImageWithNames(train_generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow import keras\nfrom sklearn import set_config\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as ImgDataGen\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D, Activation, BatchNormalization\nfrom tensorflow.keras.models import Sequential, load_model\n\nfrom tensorflow.keras import layers, optimizers, metrics, regularizers, models\nfrom tensorflow.keras.optimizers import Adam, Adamax\n# from tensorflow.keras.metrics import categorical_crossentropy, sparse_categorical_crossentropy\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define the image shape for the input layer\ninput_shape=(target_size[0], target_size[1], 3)\nbatch_size = batch_size\nepochs=60\nask_epoch=60\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nmodel_name='EfficientNetB3'\nbase_model=tf.keras.applications.efficientnet.EfficientNetB3(\n                                                            include_top=False, \n                                                            weights=\"imagenet\",\n                                                            input_shape=input_shape, \n                                                            pooling='max'\n                                                            ) \n\n# Let's make our base_model trainable to get better results\nbase_model.trainable=True\nx=base_model.output\n\nx=BatchNormalization(\n                    axis=-1, \n                    momentum=0.99, \n                    epsilon=0.001,\n                    name='batch_norm_x' \n                    )(x)\nx = Dense(\n          256, \n          kernel_regularizer = regularizers.l2(l = 0.016),\n          activity_regularizer=regularizers.l1(0.006),\n          bias_regularizer=regularizers.l1(0.006),\n          activation='relu',\n          name='dense_x'\n          )(x)\n\nx=Dropout(\n          rate=.4, \n          seed=123,\n          name='dropout_x'\n          )(x) \n      \noutput=Dense(\n            class_count, \n            activation='softmax',\n            name='dense_output'\n            )(x)\ncnn_model=Model(inputs=base_model.input, outputs=output, name=model_name)\nlearning_rate=.001 # start with this learning rate\ncnn_model.compile(\n                  Adamax(learning_rate=learning_rate), \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy']\n                  )\n\n# View the model summary\ncnn_model.summary()","metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Code by https://www.kaggle.com/code/gpiosenka/callback-to-continue-or-halt-training-f1-90\nclass ASK(keras.callbacks.Callback):\n    def __init__ (self, model, epochs,  ask_epoch): # initialization of the callback\n        super(ASK, self).__init__()\n        self.model=model               \n        self.ask_epoch=ask_epoch\n        self.subask_epoch = int(ask_epoch/2)\n        self.epochs=epochs\n        self.ask=True # if True query the user on a specified epoch\n        \n    def on_train_begin(self, logs=None): # this runs on the beginning of training\n        if self.ask_epoch == 0: \n            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n            self.ask_epoch=1\n        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n            self.ask=False # do not query the user\n        if self.epochs == 1:\n            self.ask=False # running only for 1 epoch so do not query user\n        else:\n            print('Training will proceed until epoch', ask_epoch,' then you will be asked to') \n            print(' enter H to halt training or enter an integer for how many more epochs to run then be asked again')  \n        self.start_time= time.time() # set the time at which training started\n        \n    def on_train_end(self, logs=None):   # runs at the end of training     \n        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted         \n        hours = tr_duration // 3600\n        minutes = (tr_duration - (hours * 3600)) // 60\n        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n        print (msg, flush=True) # print out training duration time\n        \n    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n        \n        if self.ask: # are the conditions right to query the user?\n            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n                print('\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again')\n                ans=input()\n                \n                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n                    print ('you entered ', ans, ' Training halted on epoch ', epoch+1, ' due to user input\\n', flush=True)\n                    self.model.stop_training = True # halt training\n                else: # user wants to continue training\n                    self.ask_epoch += int(ans)\n                    if self.ask_epoch > self.epochs:\n                        print('\\nYou earlier specified a maximum epochs of ', self.epochs, '\\n, its seems that you want to train for a total of', self.ask_epoch,'\\n\\n Please confirm your action, please enter \"Y\", or \"N\" to end training at ', self.epochs)\n                        ans=input()\n                        \n                        if ans == 'Y' or ans =='y':\n                            self.epochs = self.ask_epoch\n                        else:\n                             print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n                    else:\n                        print ('you entered ', ans, ' Training will continue to epoch ', self.ask_epoch, flush=True)\n                        \nask=ASK(cnn_model, epochs,  ask_epoch)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# starting the Checkpoint for the model\n# checkpoint_dir = os.path.dirname(checkpoint_path)\n\ncheck_point = tf.keras.callbacks.ModelCheckpoint(\n                                          filepath=checkpoint_path(model_name),\n                                          save_weights_only=True,\n                                          save_best_only=True, \n                                          monitor=\"val_accuracy\",\n                                          verbose = 1,\n                                        )\n\nreduce_learning = tf.keras.callbacks.ReduceLROnPlateau(\n                                            monitor=\"val_accuracy\", \n                                            # factor=0.5, \n                                            patience=2,\n                                            verbose=1\n                                            )\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n                                       monitor=\"val_accuracy\", \n                                       min_delta=0.0005,\n                                       patience=11, \n                                       verbose=1,\n                                       restore_best_weights=True\n                                       )\n\ncallbacks = [\n            check_point,\n            reduce_learning, \n            early_stop, \n            ask\n          ]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_history=cnn_model.fit(\n                  train_generator,  \n                  steps_per_epoch=train_generator.n//train_generator.batch_size,\n                  epochs=epochs, \n                  verbose=1, \n                  callbacks=callbacks,  \n                  validation_data=validation_generator,\n                #   validation_steps=None, \n                  validation_steps= validation_generator.n//validation_generator.batch_size,\n                #   validation_data=test_generator,\n                # #   validation_steps=None, \n                #   validation_steps= test_generator.n//test_generator.batch_size,\n                #   # shuffle=True,  \n                  )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pylab import rcParams\nacc = model_history.history['accuracy']\nval_acc = model_history.history['val_accuracy']\nloss = model_history.history['loss']\nval_loss = model_history.history['val_loss']\nstart_epoch = 0\nEpoch_count=len(acc)+ start_epoch\nEpochs=[]\nfor i in range (start_epoch ,Epoch_count):\n    Epochs.append(i+1)   \nindex_loss=npy.argmin(val_loss)   #   this is the epoch with the lowest validation loss\nval_lowest=val_loss[index_loss]\nindex_acc=npy.argmax(val_acc)\n\n\n# summarize history for accuracy using reLU\nsns.set()\nplt.figure(figsize=(20, 15))\nplt.subplot(2, 2, 1)\nplt.plot(acc)\nplt.plot(val_acc)\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\n\n\n# summarize history for loss using reLU\nplt.subplot(2, 2, 2)\nplt.plot(loss)\nplt.plot(val_loss)\nplt.title('Training and Validation Loss', fontsize=35)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load the weights from the saved checkpoint and evaluate","metadata":{}},{"cell_type":"code","source":"# Loads the weights\ncnn_model.load_weights(checkpoint_path(model_name=model_name))\n\n# Re-evaluate the model\nloss, acc = cnn_model.evaluate(validation_generator, verbose=2)\nprint(\"Restored model, validation accuracy: {:5.2f}%\".format(100 * acc))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# \ndef ModelPredictionOnTestDataset(test_generator):\n#     test_steps= test_generator.n//test_generator.batch_size\n    y_pred= []\n    y_label=test_generator.labels\n    classes=list(train_generator.class_indices.keys())\n    class_count=len(classes)\n    wrong_predictions=0\n    \n    # predict on the test set\n    preds=cnn_model.predict(test_generator, test_steps, verbose=1) \n    \n    total_predictions=len(preds)\n    print(f'total prediction: {total_predictions}')\n    for i, p in enumerate(preds):\n            pred_index=npy.argmax(p)  \n            # labels are integer values       \n            true_index=test_generator.labels[i]  \n            if pred_index != true_index:       \n                # a misclassification has occurred                                     \n                wrong_predictions=wrong_predictions + 1\n            y_pred.append(pred_index)\n    acc=( 1-wrong_predictions/total_predictions) * 100\n    print(f'\\n{wrong_predictions} out of {total_predictions} tested images could not be detected properly.\\nAccuracy of {acc:6.2f}\\n')\n    ypred=npy.array(y_pred)\n    ytrue=npy.array(y_label)\n    if class_count <=30:\n        cm = confusion_matrix(ytrue, ypred )\n        # plot the confusion matrix\n        plt.figure(figsize=(12, 8))\n        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n        plt.xticks(npy.arange(class_count)+.5, classes, rotation=90)\n        plt.yticks(npy.arange(class_count)+.5, classes, rotation=0)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.title(\"Confusion Matrix on Validation Data\", fontsize=40)\n        plt.show()\n    clr = classification_report(y_label, y_pred, target_names=classes, digits= 5) # create classification report\n    print(\"Classification Report on Validation Data:\\n-------------------------------------\\n\", clr)\n\n#     # Plot the confusion matrix\n#         ConfusionMatrix(\n#                         label_test=ytrue, \n#                         label_prep=ypred, \n#                         class_count=class_count, \n#                         class_keys=class_keys, \n#                         heada=' for Entire Test Set'\n#                         )\n        \n    return wrong_predictions, total_predictions\n\nwrong_predictions, total_predictions = ModelPredictionOnTestDataset(validation_generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Code by Hitesh Kumar https://www.kaggle.com/hitzz97/emotion-detection\n\n\ntest_images, test_labels = next(test_generator_shuffled)\npreds = cnn_model.predict(test_images)\n# print(preds)\nidx = npy.argmax(preds, axis = 1)\n# test_labels = test_labels.astype(int)\ntest_labels = npy.argmax(test_labels, axis = 1)\nidx = idx.reshape((-1, 1))\ntest_labels = npy.reshape(test_labels, (len(test_labels), 1))\n# print()\nprint('correct prediction:', npy.sum((test_labels == idx)*1)/test_batch_size)\n\n\ndef compare(idx, train_generator):\n    class_dictionary = train_generator.class_indices\n    for key, value in class_dictionary.items():\n        if value == idx:\n             return key\n\ndef dif(test_labels, idx, train_generator):    \n    class_dictionary = train_generator.class_indices\n    test = ''\n    id = ''\n    for key, value in class_dictionary.items():\n        if value == test_labels:\n            test = key\n        if value == idx:\n            id = key\n    return test, id\n\n\n\nfig = plt.figure(figsize=((20, 30)))\n\n# k = 0\nfor j in range(len(idx)):\n    ax = plt.subplot(7, 5, j+1)\n    px = test_images[j]/255\n#     k += 1\n    ax.imshow(px)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    \n#     print(idx[j])\n#     print(test_labels[j])\n    if test_labels[j] == idx[j]:\n        for axis in ['top','bottom','left','right']:\n            ax.spines[axis].set_linewidth(15)\n            ax.spines[axis].set_color('green')\n        ax.set_title(\n                    compare(idx[j], train_generator),\n                    color='green', \n                    fontsize=40\n                     )\n\n    else:\n        for axis in ['top','bottom','left','right']:\n            ax.spines[axis].set_linewidth(15)\n            ax.spines[axis].set_color('red')\n        ax.set_title(\n                    'Pred:'+dif(test_labels[j], idx[j], train_generator)[1]+\" | Act:\"+ dif(test_labels[j], idx[j], train_generator)[0],\n                    color='red', \n                    fontsize=40\n                    )\n    plt.tight_layout()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}