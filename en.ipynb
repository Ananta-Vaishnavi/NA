{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10585265,"sourceType":"datasetVersion","datasetId":6550772}],"dockerImageVersionId":30066,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport skimage.io\nimport keras.backend as K\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization ,Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom keras.applications.nasnet import NASNetLarge\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n                                   validation_split = 0.2,\n                                  \n        rotation_range=5,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        #zoom_range=0.2,\n        horizontal_flip=True,\n        vertical_flip=True,\n        fill_mode='nearest')\n\nvalid_datagen = ImageDataGenerator(rescale = 1./255,\n                                  validation_split = 0.2)\n\ntest_datagen  = ImageDataGenerator(rescale = 1./255\n                                  )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset  = train_datagen.flow_from_directory(directory = '/kaggle/input/final-dataset/Train',\n                                                   target_size = (48,48),\n                                                   class_mode = 'categorical',\n                                                   subset = 'training',\n                                                   batch_size = 64)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_dataset = valid_datagen.flow_from_directory(directory = '/kaggle/input/final-dataset/Train',\n                                                  target_size = (48,48),\n                                                  class_mode = 'categorical',\n                                                  subset = 'validation',\n                                                  batch_size = 64)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = test_datagen.flow_from_directory(directory = '/kaggle/input/final-dataset/Test',\n                                                  target_size = (48,48),\n                                                  class_mode = 'categorical',\n                                                  batch_size = 64)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_dataset.class_indices)\nprint(valid_dataset.class_indices)\nprint(test_dataset.class_indices)  # Should match train/valid datasets\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.preprocessing import image\nimg = image.load_img(\"/kaggle/input/final-dataset/Test/fear/aug_122_image0003849.jpg\",target_size=(48,48))\nimg = np.array(img)\nplt.imshow(img)\nprint(img.shape)\n\nimg = np.expand_dims(img, axis=0)\nfrom keras.models import load_model\nprint(img.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model = tf.keras.applications.EfficientNetB0(input_shape=(48,48,3),include_top=False,weights=\"imagenet\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Freezing Layers\n\nfor layer in base_model.layers[:-4]:\n    layer.trainable=False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Building Model\n\n# Define the number of classes\nnum_classes = 6\n\n# Build the model\nmodel = Sequential()\nmodel.add(base_model)  # Add the pre-trained model\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(32, kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))  # Output layer for 6 classes\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Summary\n\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png') ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def f1_score(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n    return f1_val","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc'),\n        f1_score,\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 20,verbose = 1,factor = 0.50, min_lr = 1e-10)\n\nmcp = ModelCheckpoint('model.h5')\n\nes = EarlyStopping(verbose=1, patience=20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_dataset,\n    validation_data=valid_dataset,\n    epochs=50,\n    verbose=1,\n    callbacks=[lrd, mcp, es]\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%% PLOTTING RESULTS (Train vs Validation FOLDER 1)\n\ndef Train_Val_Plot(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,f1,val_f1):\n    \n    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))\n    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('History of Accuracy')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('History of Loss')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Loss')\n    ax2.legend(['training', 'validation'])\n    \n    ax3.plot(range(1, len(auc) + 1), auc)\n    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n    ax3.set_title('History of AUC')\n    ax3.set_xlabel('Epochs')\n    ax3.set_ylabel('AUC')\n    ax3.legend(['training', 'validation'])\n    \n    ax4.plot(range(1, len(precision) + 1), precision)\n    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n    ax4.set_title('History of Precision')\n    ax4.set_xlabel('Epochs')\n    ax4.set_ylabel('Precision')\n    ax4.legend(['training', 'validation'])\n    \n    ax5.plot(range(1, len(f1) + 1), f1)\n    ax5.plot(range(1, len(val_f1) + 1), val_f1)\n    ax5.set_title('History of F1-score')\n    ax5.set_xlabel('Epochs')\n    ax5.set_ylabel('F1 score')\n    ax5.legend(['training', 'validation'])\n\n\n    plt.show()\n    \n\nTrain_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n               history.history['loss'],history.history['val_loss'],\n               history.history['auc'],history.history['val_auc'],\n               history.history['precision'],history.history['val_precision'],\n               history.history['f1_score'],history.history['val_f1_score']\n              )","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}