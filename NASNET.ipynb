{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":10548423,"sourceType":"datasetVersion","datasetId":6526617},{"sourceId":10568680,"sourceType":"datasetVersion","datasetId":6539858}],"dockerImageVersionId":30408,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install facenet-pytorch\n!pip install torch torchvision\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications import NASNetLarge\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.nasnet import preprocess_input\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configuration\nIMG_HEIGHT, IMG_WIDTH = 331, 331\nBATCH_SIZE = 32\nEPOCHS = 50\nLEARNING_RATE = 0.0001\nMOMENTUM = 0.9\nL2_REGULARIZATION = 0.001\nMODEL_SAVE_PATH = \"nasnet_large_emotion_model.h5\"\nDATASET_DIR = \"/kaggle/input/affectnet-cleaned\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Augmentation\ndef create_data_generators(dataset_dir):\n    datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_input,\n        rotation_range=20,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        validation_split=0.2  # 80% training, 20% validation\n    )\n\n    train_gen = datagen.flow_from_directory(\n        os.path.join(dataset_dir, \"Train\"),\n        target_size=(IMG_HEIGHT, IMG_WIDTH),\n        batch_size=BATCH_SIZE,\n        class_mode=\"categorical\",\n        subset=\"training\"\n    )\n\n    val_gen = datagen.flow_from_directory(\n        os.path.join(dataset_dir, \"Train\"),\n        target_size=(IMG_HEIGHT, IMG_WIDTH),\n        batch_size=BATCH_SIZE,\n        class_mode=\"categorical\",\n        subset=\"validation\"\n    )\n\n    return train_gen, val_gen","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build NasNet Large Model with Correct Metrics\ndef build_nasnet_large(num_classes):\n    base_model = NASNetLarge(weights=\"imagenet\", include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    output = Dense(num_classes, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(L2_REGULARIZATION))(x)\n\n    model = Model(inputs=base_model.input, outputs=output)\n\n    # Freeze the base model for initial training\n    base_model.trainable = False\n\n    # Compile the model with accuracy as a metric\n    model.compile(\n        optimizer=SGD(learning_rate=LEARNING_RATE, momentum=MOMENTUM),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]  # Removed 'loss'\n    )\n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Training History\ndef plot_training_history(history):\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n    plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n    plt.title(\"Accuracy\")\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n    plt.title(\"Loss\")\n    plt.legend()\n\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_gen, val_gen = create_data_generators(DATASET_DIR)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build the NasNetLarge model\nmodel = build_nasnet_large(train_gen.num_classes)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS,\n    verbose=2\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the model\nmodel.save(MODEL_SAVE_PATH)\nprint(f\"Model saved to {MODEL_SAVE_PATH}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training history\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fine-tune the base model (optional)\nprint(\"Fine-tuning the base model...\")\nmodel.layers[0].trainable = True  # Unfreeze the base model\nmodel.compile(\n    optimizer=SGD(learning_rate=LEARNING_RATE / 10, momentum=MOMENTUM),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\nhistory_ft = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS // 2,\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save fine-tuned model\nmodel.save(\"nasnet_large_finetuned.h5\")\nprint(\"Fine-tuned model saved!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}